{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb096636-8170-479f-b014-51dfe030c12a",
   "metadata": {},
   "source": [
    "# Introduction to Scikit-Lean (sklearn)\n",
    "\n",
    "This notebook demonstrates some of the most useful functions of the beautiful SciKit-Learn library.\n",
    "\n",
    "What we're going to cover:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b66ff7f-9ce4-4251-aac0-7fc431bb3d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's listify the content\n",
    "what_were_covering = [\n",
    "\"0. An end-to-end SckiKit-Learn workflow\",\n",
    "\"1. Getting the data ready\",\n",
    "\"2. Choose the right estimator/algorithm for our problems\",\n",
    "\"3. Fit the model/algorith and use it to make predictions on our data\",\n",
    "\"4. Evaluating a model\",\n",
    "\"5. improve a model\",\n",
    "\"6. save and load a trained model\",\n",
    "\"7. putting it all together!\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b7df762-ae2f-4b7e-9540-33a2e00a1843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c903930f-d121-423e-a1c9-e214188c44c7",
   "metadata": {},
   "source": [
    "## 0. An end-to-end SciKit-Learn workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbf2655f-4e96-46a8-adf6-4f4adc74396b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Get the data ready\n",
    "\n",
    "heart_disease = pd.read_csv(\"./data/heart-disease.csv\");\n",
    "heart_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ba497c1-abe7-4859-9802-da079dc00410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X (features matrix)\n",
    "x = heart_disease.drop(\"target\", axis=1)\n",
    "\n",
    "# create y (labels)\n",
    "y = heart_disease[\"target\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa9b034e-3d0c-4cc8-bd07-0d8736ec7136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'monotonic_cst': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 Choose the right model and hyperparameters\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# We'll keep the default hyperparameters\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "177299f9-ab87-493f-830e-429cbc0c6b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbf5c739-5836-4ba3-8b17-0e34aeb2389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "523b85d4-4e12-433e-bcc7-84c5e92b9b7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# make a prediction\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m y_label = clf.predict(\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[31mTypeError\u001b[39m: 'builtin_function_or_method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "y_label = clf.predict(np.array[0,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef2974a-aca5-4799-8f4e-b92a6011f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2605b5a-3b6e-4a79-9113-30579e8dccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06d5b32-eca8-4e71-a7d4-1e5d0f4ca4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1440467-3281-4f72-b506-5d7bb7ae75d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Evaluate the model on the training data and test data\n",
    "clf.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c1ecb0-e37b-45aa-afcb-18b25f2fe107",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109c3900-6d49-43b9-9e94-ab29a593d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e637c49-5cc7-4812-a7fe-571a1f65667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585640d2-184b-4fd7-84f1-0f7d17a4d762",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4362e857-e5cf-4be3-b1b9-105eb5a75509",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54a12ff-9c7b-423d-a185-9dd99aff2062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Improve a model\n",
    "# try different amount of n_estimators\n",
    "\n",
    "np.random.seed(42)\n",
    "for i in range(10, 100, 10):\n",
    "    print(f\"Trying model with {i} estimators...\")\n",
    "    clf = RandomForestClassifier(n_estimators=i).fit(x_train, y_train)\n",
    "    print(f\"Model accuracy on test set: {clf.score(x_test, y_test) * 100:.2f}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4beafff-766f-492e-abdd-066f029bd8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Save a model and load it\n",
    "import pickle\n",
    "\n",
    "pickle.dump(clf, open(\"random_forest_model_1.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b9f708-10a6-4da5-b973-795c8975b85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"random_forest_model_1.pkl\", \"rb\"))\n",
    "loaded_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90923221-3edf-42bd-9c03-09abd4ccdaca",
   "metadata": {},
   "source": [
    "## 1. Getting our data ready to be used with machine learning\n",
    "Three main things we have to do:\n",
    "* 1. Split the data into features and labels (usually \"x\" & \"y\")\n",
    "  2. Filling (also called imputing) or disregarding missing values\n",
    "  3. converting non-numerical values to numerical values (also called feature encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e980b-ac3c-45e9-a29b-a3d9ae53fba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec5afeb-b5dd-4fcd-baf9-330ed0faf443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "x = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f522b98f-6087-4b22-baf6-9d3eb3d23bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, y_train, x_test, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12f95c9-3057-4945-987b-1cd648d86329",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b54f7d-baa4-48e7-b72e-6e55d66d1c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd82984e-cafc-4a0d-9bc3-857c9809e034",
   "metadata": {},
   "source": [
    "## 1.1 Make sure it's all numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542076cc-9bc8-44c4-8954-db8ad2c51e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales = pd.read_csv(\"./data/car-sales-extended.csv\")\n",
    "len(car_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a9aeed-02e2-4113-939f-d50e0835f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6608b91e-6fb9-4045-9c35-606590568f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into x/y\n",
    "x = car_sales.drop(\"Price\", axis = 1)\n",
    "y = car_sales[\"Price\"]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f41811e-19c1-4d33-8f19-d29834607502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217c0863-8aa2-4115-a2a6-0f0de238a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea96cf7-36bc-4cde-9da1-bd39791203d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build machine learning model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced8016c-deb9-47f1-a41b-60b1d10fc92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer(\n",
    "    [(\"one_hot\", one_hot, categorical_features)],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "transformed_x = transformer.fit_transform(x)\n",
    "transformed_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df371db-6023-40df-ad59-4149c8e42c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(transformed_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba323c48-42dc-4c26-a3d2-eb85b64ea979",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(car_sales[[\"Make\", \"Colour\", \"Doors\"]])\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8d35c8-520d-4332-b332-393b32a58232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's refit the model\n",
    "np.random.seed(42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(transformed_x, y, test_size=0.2)\n",
    "model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a799d0-6e4b-4336-9571-8a091c652efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e9a563-0a57-480f-9a54-39d9841e9360",
   "metadata": {},
   "source": [
    "### 1.2 What if there were missing values?\n",
    "\n",
    "1. Fill them with some values (aka imputation).\n",
    "2. Remove the samples with missing data altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7f2545-b908-4ddc-9e0c-3f365d4128ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import car sales missing data\n",
    "car_sales_missing = pd.read_csv(\"./data/car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c287b092-c8de-49e1-a7dd-aa525de4202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create x and y\n",
    "x = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf29a58-d0c8-4db7-a0b0-9f7d5dff4de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer(\n",
    "    [(\"one_hot\", one_hot, categorical_features)],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "transformed_x = transformer.fit_transform(x)\n",
    "transformed_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d212287f-3140-49e4-988e-1aeb47415478",
   "metadata": {},
   "source": [
    "### Option 1: Fill missing data with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c917a9-cbd9-49a9-8d86-42609186d42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588a1d95-09e0-43a9-b3ed-ea476fe153a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing[\"Doors\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa10e911-7926-40bb-9e53-04d2f0fa46b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the \"Make\" column\n",
    "car_sales_missing[\"Make\"] = car_sales_missing[\"Make\"].fillna(\"missing\")\n",
    "\n",
    "# Fill the \"Colour\" column\n",
    "car_sales_missing[\"Colour\"] = car_sales_missing[\"Colour\"].fillna(\"missing\")\n",
    "\n",
    "# Fill the \"Odometer (KM)\" column\n",
    "car_sales_missing[\"Odometer (KM)\"] = car_sales_missing[\"Odometer (KM)\"].fillna(round(car_sales_missing[\"Odometer (KM)\"].mean(), 1))\n",
    "\n",
    "# Fill the \"Doors\" column\n",
    "car_sales_missing[\"Doors\"] = car_sales_missing[\"Doors\"].fillna(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31ad5f6-734d-4461-bf20-9e77f8260a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dataframe again\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a066e35-fa30-46bf-8583-79be74499dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing price value\n",
    "car_sales_missing = car_sales_missing.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d01966-8ece-4428-a202-7cb7444b6f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50140cd-dc6b-45a3-a6e0-8f2dba45558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(car_sales_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29280522-9d4e-4276-84aa-192fbd767691",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24ffe07-9259-4a8a-b378-7e312c3dbce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer(\n",
    "    [(\"one_hot\", one_hot, categorical_features)],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "transformed_x = transformer.fit_transform(car_sales_missing)\n",
    "transformed_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053b2b84-585e-4cdf-9fe1-d92a47155e0a",
   "metadata": {},
   "source": [
    "### Option 2: Fill missing values with SciKit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c334b87-ed32-454d-a2ff-ca5b162c0b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing = pd.read_csv(\"./data/car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca69ae33-50fa-4018-9920-ee9395112fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with no price\n",
    "car_sales_missing = car_sales_missing.dropna(subset=[\"Price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ec0725-198d-4553-af31-5cae4347bf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca0775a-daca-4e75-920c-c37c5aeee958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into x & y\n",
    "x = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb95c0ca-1d9d-4967-9cf8-af4433394d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with SciKit-Learn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Fill categorical values with \"missing\" & numerical values with mean\n",
    "cat_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"missing\")\n",
    "door_imputer = SimpleImputer(strategy=\"constant\", fill_value=4)\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "# Define columns\n",
    "cat_features = [\"Make\", \"Colour\"]\n",
    "door_feature = [\"Doors\"]\n",
    "num_features = [\"Odometer (KM)\"]\n",
    "\n",
    "# Create an imputer (something that fills missing data)\n",
    "imputer = ColumnTransformer([\n",
    "    (\"cat_imputer\", cat_imputer, cat_features),\n",
    "    (\"door_imputer\", door_imputer, door_feature),\n",
    "    (\"num_imputer\", num_imputer, num_features)\n",
    "])\n",
    "\n",
    "# Transform the data\n",
    "filled_x = imputer.fit_transform(x)\n",
    "filled_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11d2e96-c6ee-4220-b872-e922078987cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_filled = pd.DataFrame(\n",
    "    filled_x, \n",
    "    columns=[\"Make\", \"Colour\", \"Doors\", \"Odometer (KM)\"]\n",
    ")\n",
    "car_sales_filled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e511bef8-71c3-454e-a2bf-8c26fc9feebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6780bad1-9fba-48a4-827b-1911fe240da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer(\n",
    "    [(\"one_hot\", one_hot, categorical_features)],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "transformed_x = transformer.fit_transform(car_sales_filled)\n",
    "transformed_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff985eab-e440-4934-8dc3-1417e057bb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we've got our data as numbers and filled (no missing values)\n",
    "# Let's fit a model\n",
    "\n",
    "np.random.seed(42)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    transformed_x,\n",
    "    y,\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2107000-8e8a-43da-a46b-df0fc7f0562e",
   "metadata": {},
   "source": [
    "## 2. Choosing the righr estimator/algorithm for your problem\n",
    "\n",
    "Some things to note:\n",
    "\n",
    "* Sklearn refers to machine learning models, algorithms as estimators.\n",
    "* Classification problem - predicting a category (heart disease or not)\n",
    "    * Sometimes you'll see \"clf\" (short for classifier) used as a classification estimator\n",
    "* Regression problem - predicting a number (selling price of a car)\n",
    "\n",
    "If you're working on a machine learning problem using Sklearn and not sure what model to use, refer to the sklearn machine learning map:\n",
    "https://scikit-learn.org/stable/machine_learning_map.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcb23df-8790-425a-8408-2f442a21854d",
   "metadata": {},
   "source": [
    "### 2.1 Picking a machine learning model for a regression problem\n",
    "Let's use the California housing dataset - https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f851977-99eb-46de-91e3-7c08cba70662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "           37.88      , -122.23      ],\n",
       "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "           37.86      , -122.22      ],\n",
       "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "           37.85      , -122.24      ],\n",
       "        ...,\n",
       "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "           39.43      , -121.22      ],\n",
       "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "           39.43      , -121.32      ],\n",
       "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "           39.37      , -121.24      ]], shape=(20640, 8)),\n",
       " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894], shape=(20640,)),\n",
       " 'frame': None,\n",
       " 'target_names': ['MedHouseVal'],\n",
       " 'feature_names': ['MedInc',\n",
       "  'HouseAge',\n",
       "  'AveRooms',\n",
       "  'AveBedrms',\n",
       "  'Population',\n",
       "  'AveOccup',\n",
       "  'Latitude',\n",
       "  'Longitude'],\n",
       " 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 20640\\n\\n:Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n:Attribute Information:\\n    - MedInc        median income in block group\\n    - HouseAge      median house age in block group\\n    - AveRooms      average number of rooms per household\\n    - AveBedrms     average number of bedrooms per household\\n    - Population    block group population\\n    - AveOccup      average number of household members\\n    - Latitude      block group latitude\\n    - Longitude     block group longitude\\n\\n:Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nA household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surprisingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. rubric:: References\\n\\n- Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n  Statistics and Probability Letters, 33:291-297, 1997.\\n'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab269fb2-7d71-440d-a9fa-977cd1d2aaba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  \n",
       "0        -122.23  \n",
       "1        -122.22  \n",
       "2        -122.24  \n",
       "3        -122.25  \n",
       "4        -122.25  \n",
       "...          ...  \n",
       "20635    -121.09  \n",
       "20636    -121.21  \n",
       "20637    -121.22  \n",
       "20638    -121.32  \n",
       "20639    -121.24  \n",
       "\n",
       "[20640 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df = pd.DataFrame(housing[\"data\"], columns=housing[\"feature_names\"])\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ea72ffa-98ea-40d6-896b-2a2239dcc60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df[\"target\"] = housing[\"target\"]\n",
    "# housing_df = housing_df.drop(\"MedHouseVal\", axis=1)\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9c94a4-69b4-4ba6-a7db-9d1a5b87d510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression Model\n",
    "\n",
    "# import algorithm/estimator\n",
    "from sklearn.linear_model import Ridge\n",
    "# setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# create the data\n",
    "x = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# split into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# instantiate an fit model (on the training set)\n",
    "model = Ridge()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# score the model\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15f7fae-c643-4148-a12e-0321cc3c77cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Model\n",
    "\n",
    "# import algorithm/estimator\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# create the data\n",
    "x = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# split into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# instantiate and fit a model\n",
    "model = Lasso()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# score model\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103dcb19-6571-4faf-a2ca-feae708c50a7",
   "metadata": {},
   "source": [
    "### Ensemble model\n",
    "An ensemble is a combination of smaller models to try and make better predictions than just a single model\n",
    "Sklearn's ensemble models can be found here: https://scikit-learn.org/stable/modules/ensemble.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee60c657-61b5-4622-8f1a-6575f1db7af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestRegressor model class from the ensemble module \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# create the data\n",
    "x = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# split into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# create random forest model\n",
    "model = RandomForestRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# score the model\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dd5b6e-9c4b-4748-b7e9-6342ee430205",
   "metadata": {},
   "source": [
    "### 2.2 Picking a machine learning model for a classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74181518-c07f-42d8-802f-9d36e927e586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wine dataset\n",
    "from sklearn.datasets import load_wine\n",
    "data = load_wine()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2567b5a6-6132-4d5a-a298-24a12dd1eae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "wine_df[\"target\"] = data[\"target\"]\n",
    "wine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b69ee5-33b6-4da8-9379-b19468796bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import LinearSVC model\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# create the data\n",
    "x = wine_df.drop(\"target\", axis=1)\n",
    "y = wine_df[\"target\"]\n",
    "\n",
    "# split data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# create the model\n",
    "model = LinearSVC()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# score the model\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4930d211-8be6-467c-b7c0-54acee00f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease = pd.read_csv(\"./data/heart-disease.csv\")\n",
    "heart_disease.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce4e9fd-ed4b-426b-b549-e1815e0c0268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the LinearSVC estimator class\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# create the data\n",
    "x = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# split the data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# create the model\n",
    "clf = LinearSVC()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate the LinearSVC\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a153e6-7492-48f4-b0da-978a5cead880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestClassifier estimator class\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# create the data\n",
    "x = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# split the data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# create the model\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate the Random Forest Classifier\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903582dd-fe27-4a7b-8765-c2d7b9480ba1",
   "metadata": {},
   "source": [
    "Tidbit:\n",
    "\n",
    "    * 1. If you have structured data, use ensemble methods (tables)\n",
    "    * 2. If you have unstructured data, use deep learning or transfer learning (images, audio, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4723e954-d515-4863-8f08-607d314031fd",
   "metadata": {},
   "source": [
    "## 3. Fit the model/algorithm on our data and use it to make predictions\n",
    "\n",
    "### 3.1 Fitting the model to the data\n",
    "\n",
    "Different names for:\n",
    "X = features, features variables, data\n",
    "y = labels, targets, target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc97836-b4bb-48ce-a815-91d0cbdc707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestClassifier estimator class\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# create the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Fit the model to the data (training the machine learning model)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the Random Forest Classifier (use the patterns the model has learned)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7f3a77-7cae-4540-8985-88eb356629ac",
   "metadata": {},
   "source": [
    "### 3.2 Make predictions using a machine learning model\n",
    "\n",
    "2 ways to make predictions:\n",
    "1. \"predict()\"\n",
    "2. \"predict_proba()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f3601a-5d97-484a-a24e-ca47b454f1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a trained model to make predictions\n",
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e43498-0051-4d65-b66f-a61a13b313c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bac85c3-d9c2-4c6e-a7bc-3424e238eeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predictions to truth labels to evaluate the model\n",
    "y_preds = clf.predict(X_test)\n",
    "np.mean(y_preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a2888e-f4d2-4bc8-83a3-fc989171eadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c3d5cb-8a66-43fb-bfad-5447598cde33",
   "metadata": {},
   "source": [
    "Make predictions with `predict_proba()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c187af05-213f-45a0-a1b1-0d513204c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  predict_proba() return probabilities of a classfification label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbd8f54-f21e-411a-bdc1-4ab4e7843871",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict_proba(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ed49f9-e128-4b36-b179-961f1682c034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's predict on the same data...\n",
    "clf.predict(X_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31503744-aaed-4ab0-8d9a-5b15a65eef5e",
   "metadata": {},
   "source": [
    "`predict()` can also be used for regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0917c0b-6407-48a4-bc69-6845e5d86835",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e070384d-653d-4eed-a148-3b57d90f15c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestRegressor model class from the ensemble module \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# create the data\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# create random forest model\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# score the model\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccf5159-e6a5-42e7-9758-fa81029efe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_preds = model.predict(X_test)\n",
    "y_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53803c7-cec0-44ef-b749-9238e471b51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ed35c8-b96e-432e-a08a-06e909b622da",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20a430c-ce72-447f-8b6f-ee807c4be4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the predictions to the truth\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9401602e-0966-4bbe-9a27-0f0c7efbccc2",
   "metadata": {},
   "source": [
    "## 4. Evaluating a machine learning model\n",
    "\n",
    "Three ways to evaluate SciKit-Learn models/estimators:\n",
    "1. Estimator's built in `score()` method\n",
    "2. The `scoring` parameter\n",
    "3. Problem specific metric function\n",
    "\n",
    "You can read more about these here: https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d63b25-9506-4e91-8b6e-4a57f279da39",
   "metadata": {},
   "source": [
    "### 4.1 Evaluating a model with the `score()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c897f857-1ddc-4491-a266-2df074621f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier algorithm\n",
    "\n",
    "# import model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# create the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# fit the model\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#score the model\n",
    "clf.score(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae0b883-0b08-4464-8b55-de5289c6966a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressor algorithm\n",
    "\n",
    "# import the model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# create the data\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# fit the model\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# score the model\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c199a75-3124-4445-a345-668f82cfe1fd",
   "metadata": {},
   "source": [
    "### 4.2 Evaluating a model using `scoring` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9e8a98-e361-4070-a92c-92448835e12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# import model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# create the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# fit the model\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d85e524-7228-4635-b7f6-96efd97a7ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e42481-336e-4ff3-a133-7dd7871d2e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(clf, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce44b0d4-9862-451a-ae2e-343e4447bdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare single score and cross val score\n",
    "np.random.seed(42)\n",
    "\n",
    "# Single training and test split score\n",
    "clf_single_score = clf.score(X_test, y_test)\n",
    "\n",
    "# Take the mean of 5-fold cross-validation score\n",
    "clf_cross_val_score = np.mean(cross_val_score(clf, X, y))\n",
    "\n",
    "# compare the two\n",
    "clf_single_score, clf_cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9920283-d643-49c6-8436-a8e52e656b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default scoring parameter of classifier = mean accuracy\n",
    "clf.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b873122b-5a7f-4697-9f0d-1af26606ceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring parameter set to None by default\n",
    "cross_val_score(clf, X, y, scoring=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec66c09-1412-4514-b7bd-2604d276a09d",
   "metadata": {},
   "source": [
    "### 4.2.1 Classification model evaluation metrics\n",
    "1. Accuracy\n",
    "2. Area under ROC curve\n",
    "3. confusion matrix\n",
    "4. classification report\n",
    "\n",
    "**Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235ddb47-b4d9-464b-8e4f-6918c96e111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import classifier model \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# create the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "## score the model\n",
    "clf = RandomForestClassifier()\n",
    "cross_val_score = cross_val_score(clf, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb03c23f-1d97-4f07-a32e-9ab46a2b8fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Heart Disease Classifier Cross-Validated Accuracy: {np.mean(cross_val_score) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a644f6-c826-4c2a-a3b7-bb239b348913",
   "metadata": {},
   "source": [
    "**Area under the receiver operating characteristic curve (AUC/ROC)**\n",
    "\n",
    "* Area under curve(AUC)\n",
    "* ROC curve\n",
    "\n",
    "ROC curves are a comparison of a model's true positive rate (tpr) versus a models false positive rate (fpr).\n",
    "\n",
    "* True positive = model predicts 1 when truth is 1\n",
    "* False positive = model predicts 1 when truth is 0\n",
    "* True negative = model predicts 0 when truth is 0\n",
    "* False negative = model predicts 0 when truth is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c2dbc3-6cc9-461f-a6b5-ecb0e01d7fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# fit the model\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f537956-75fb-4043-a7f5-85314d1b0d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Make predictions with probabilities\n",
    "y_probs = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4b68da-d019-4315-a7d8-3d08e3aed940",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs[:10], len(y_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3c0d32-5643-4335-b962-783ddbb123ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_positive = y_probs[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d80d893-24c1-4196-83cd-ce7f0c8a22e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf2e5a8-9240-4119-98a1-ad102cf20fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate fpr, tpr, and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs_positive)\n",
    "\n",
    "# check the false positive rate\n",
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afa6609-a53d-4e92-9545-e12b8c5d8b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function for plotting ROC curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    \"\"\"\n",
    "    Plots a ROC curve given the false positive rate (fpr) and true positive rate (tpr) of a model.\n",
    "    \"\"\"\n",
    "    # plot the roc curve\n",
    "    plt.plot(fpr, tpr, color=\"orange\", label=\"ROC\")\n",
    "\n",
    "    # plot line with no predicitve power (baseline)\n",
    "    plt.plot([0, 1], [0, 1], color=\"darkblue\", linestyle=\"--\", label=\"Guessing\")\n",
    "\n",
    "    # customize the plot\n",
    "    plt.xlabel(\"False positive rate (fpr)\")\n",
    "    plt.ylabel(\"True positive rate (tpr)\")\n",
    "    plt.title(\"Receiver Operating Characteristics (ROC) curve\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d126c835-855d-49a1-9c2f-b6cd1de039db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e13fa1-d6b2-420b-814e-233d788f1fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, y_probs_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225b0f6d-6dad-497e-b67c-8ab8ce33443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot perfect ROC curve and AUC score\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test)\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7bfa75-bbee-4e62-9d7c-cc8418e1ed2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perfect auc score\n",
    "roc_auc_score(y_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e89ce08-0853-41ca-8ca4-df3decc1df1f",
   "metadata": {},
   "source": [
    "**Confusion Matrix**\n",
    "\n",
    "A confusion matrix is a quick way to compare the labels a model predicts and the actual labels it was supposed to predict.\n",
    "\n",
    "In essence, giving you  an idea of where the model is getting confused.\n",
    "\n",
    "SciKit documentation: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3792e94-f1a1-44f2-a78b-908cd4db9751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0424d88-31f2-42de-b28a-f26cc0f6bc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize confusion matrix with pd.crosstab()\n",
    "pd.crosstab(\n",
    "    y_test,\n",
    "    y_preds,\n",
    "    rownames=[\"Actual Labels\"],\n",
    "    colnames=[\"Predict Labels\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e72644-17e8-419c-bf97-32cbccf27185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install seaborn to conda environment\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} seaborn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e8379c-1e72-4848-8d3a-00e28ade88c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD VERSION\n",
    "# make confusion matrix more visual with seaborn's heatmap\n",
    "import seaborn as sns\n",
    "\n",
    "# set the font scale\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "# create a confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_preds)\n",
    "\n",
    "# plot using seaborn\n",
    "sns.heatmap(conf_mat);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e83f16-9a7b-4552-abb4-0b701895d2ee",
   "metadata": {},
   "source": [
    "### Creating a confusion matrix using Scikit-Learn\n",
    "\n",
    "To use the new methods of creating a confusion matrix with SkiKit-Learn you will need sklearn version 1.0+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126de371-e3c9-4db0-a404-fe5f5ab04011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check sklearn version\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18b7310-0f9b-49dd-aa16-0cb1227c2b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix from estimator (without predictions)\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(clf, X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e33830e-8e5b-44b0-9bf8-bfd8a08c53fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix from estimator (without predictions)\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_preds);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b844af-f974-4af4-ae34-4a757c75ee83",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420d01c9-097d-4bc6-81f5-1c3f1a2f99f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab29242f-7980-4ff6-bf05-e84432b3e4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where precision and recall become valuable\n",
    "disease_true = np.zeros(10000)\n",
    "disease_true[0] = 1 # only one positive case\n",
    "\n",
    "disease_preds = np.zeros(10000) # model predicts every case as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6f4749-6812-42e3-85b3-e4314524a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(classification_report(\n",
    "    disease_true,\n",
    "    disease_preds,\n",
    "    output_dict=True\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c2cc4c-943b-416c-86d4-c578a534f42a",
   "metadata": {},
   "source": [
    "### 4.2.2 Regression model evaluation metrics\n",
    "\n",
    "Model evaluation metrics - documentation: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "The ones we're going to cover are:\n",
    "1. R^2 or coefficient of determination\n",
    "2. Mean absolute error (MAE)\n",
    "3. Mean squared error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c42ae0b-01b1-4750-9b21-f58b5e0f18ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import regressor model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# create the data\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# create the model\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7fa748-ede8-4633-9e88-c929a429f310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the model\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9ecce0-4abd-47cd-b0f5-4d19ed9de9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a735c55-8102-4550-adee-47238b103feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r^2 evaluation metric\n",
    "# Compares your models predictions to the mean of the targets.\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# fill an array with y_test mean\n",
    "y_test_mean = np.full(len(y_test), y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0014a2bf-5bbf-4aca-8588-e596271b92d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc700cf9-24d2-4259-95a7-bc923bb8f45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571add84-c9ac-485b-8305-fe719bff2965",
   "metadata": {},
   "source": [
    "***Mean Absolute Error (MAE)***\n",
    "\n",
    "MAE is the average of the aboslute differences between predictions and actual values.\n",
    "\n",
    "It gives you an idea of how wrong your models predictions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1919d464-997c-44b5-b9fa-74e00456206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE mean absolute error evaluation metric\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# make predictions from model\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "# calculate MAE\n",
    "mae = mean_absolute_error(y_test, y_preds)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4e9aac-c227-474b-899d-47bd5291ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe with actual and predicted values\n",
    "df = pd.DataFrame(data={\n",
    "    \"actual values\": y_test,\n",
    "    \"predicted values\": y_preds \n",
    "})\n",
    "# calculate absolute difference between actual and predicted values\n",
    "df[\"differences\"] = abs(df[\"actual values\"] - df[\"predicted values\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ad4ad2-7ba5-4674-86fb-64b3b7695cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE using formulas and differences\n",
    "df[\"differences\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195a3889-4ed2-4b9d-8769-209efd0bda3c",
   "metadata": {},
   "source": [
    "***Mean Squared Error (MSE)***\n",
    "\n",
    "MSE is the mean of the square of the errors between actual and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8bbe10-abec-4645-af30-d491f1aa7204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE mean squared error evaluation metric\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# make predictions with model\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "# calculate MSE\n",
    "mse = mean_squared_error(y_test, y_preds)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a2a92f-656a-41b4-ab96-66f80c70d7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe with actual and predicted values\n",
    "df = pd.DataFrame({\n",
    "    \"actual values\": y_test,\n",
    "    \"predicted values\" : y_preds\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826a702a-8b16-421e-80e9-c997104838d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate squared value of difference betwen actual and predicted values\n",
    "df[\"squared difference\"] = np.square(df[\"actual values\"] - df[\"predicted values\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d30aa87-55c1-44f0-9222-ba7634879ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcualte MSE, average of squared difference    \n",
    "df[\"squared difference\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6025e00-76da-4b70-8ee7-90e466a2715d",
   "metadata": {},
   "source": [
    "## Machine Learning Model Evaluation\n",
    "\n",
    "Evaluating the results of a machine learning model is as important as building one.\n",
    "\n",
    "These are some of the most important evaluation metris you'll want to look into for classification and regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c78dc4-83fc-4a7d-971e-93959ec8c566",
   "metadata": {},
   "source": [
    "### Classification Model Evaluation Metrics/Techniques\n",
    "\n",
    "* `Accuracy` - The accuracy of the model in decimal format. Perfect accuracy is equal to 1.0\n",
    "* `Precision` - Indicates the proportion of positive identifications (model predicted class 1) which were actually correct. A model which produces no false positives has a precision of 1.0\n",
    "* `Recall` - Indicates the proportion of actual positives which were correctly classified. A model which produces no false negatives has a recall of 1.0\n",
    "* `F1 Score` - A combination of precision and recall. A perfect model achieves an F1 score of 1.0\n",
    "* `Confusion matrix` - Compares the predicted values with the true values in a tabular, if 100% correct, all values in the atrix will be top left to bottom right (diagonal line)\n",
    "* `Cross-validation` - Splits yur dataset into multiple parts and train and tests your model on each part then evaluates performance as an average\n",
    "* `Classification report` - Sklearn has a built-in function called `classification_report()` which returns some of the main classification metrics such as precision, recall and f1-score\n",
    "* `ROC Curve` - Also known as receiver operating characteristic is a plot of true positive rate versus false-positive rate\n",
    "* `Area Under Curve (AUC) Score` - The area underneath the ROC curve. A perfect model achieves an AUC score of 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e39e2f9-2cae-4788-a0a3-3bcd9bf85e9d",
   "metadata": {},
   "source": [
    "### Which classification metric should you use?\n",
    "\n",
    "* `Accuracy` is a good measure to start with if all classes are balanced (e.g. same amount of samples which are labelled with 0 or 1)\n",
    "* `Precision` and `Recall` become more important when classes are imbalanced\n",
    "* If false-positive predictions are worse than false-negatives, aim for higher `precision`\n",
    "* If false-negative predictions are worse than false-positives, aim for higher `recall`\n",
    "* `F1-score` is a combination of precision and recall\n",
    "* A `confusion matrix` is always a good way to visualize how a classification model is going"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1a7d7b-e3fa-4a4a-b529-0ade5a2054a0",
   "metadata": {},
   "source": [
    "### Regression Model Evaluation Metrics/Techniques\n",
    "\n",
    "* `R^2 or the coefficient of determination` - Compares your model's predictions to the mean of the targets. Values can range from negative infinity (a very poor model) to 1. For example, if all your model does is predict the mean of the targets, its R^2 value would be 0, if your model perfectly predicts a range of numbers it's R^2 value would be 1\n",
    "* `Mean absolute error (MAE)` - The average of the absolute differences between actual and predicted values. It gives you an idea of how wrong your predictions were\n",
    "* `Mean squared error (MSE)` - The average squared difference between predictions and actual values. Squaring the errors removes negative errors. It also amplifies outliers (samples which have larger errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89969eba-5f39-4b01-b539-99e7d1606b2f",
   "metadata": {},
   "source": [
    "### Which regression metric should you use? \n",
    "\n",
    "* `R2` is similar to accuracy. It gives you a quick inidcation of how well your model might be doing. Generally, the closer your `R2` value is to 1.0, the better the model. But it doesn't really tell exactly how wrong your model is in terms of how far off each prediction is\n",
    "* `MAE` gives a better indication of how far off each of your model's predictions are on average\n",
    "* As for `MAE` or `MSE`, because of the way MSE is calculated, squaring the differences between predicted values and actual values, it amplifies larger differences, Let's say we're predicting the value of houses:\n",
    "    * Pay more attention to `MAE`: When being \\$10,000 off is *twice* as bad as being \\$5,000 off\n",
    "    * Pay more attention to `MSE`: when being \\$10,000 off is *more than twice* as bad as being \\$5,000 off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25065cd-2051-4e64-88a2-49b06311eb86",
   "metadata": {},
   "source": [
    "### 4.2.3 Using the `scoring` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6913d35a-f20f-4484-81e4-e202aa0a2ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# create the data\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# split data into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# create the model\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ee8ce3-710f-4bde-8a6e-56fdc1571658",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Cross-validation accuracy\n",
    "cv_acc = cross_val_score(clf, X, y, scoring=\"accuracy\") #scoring=None uses models default: accuracy\n",
    "cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df81301b-8127-4aa6-831d-e0a373b913a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation accuracy\n",
    "print(f\"The Cross-validated accuracy is: {np.mean(cv_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0684b130-fef2-451a-8d8f-ba224f1c74f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Cross-validation precision\n",
    "cv_precision = cross_val_score(clf, X, y, scoring=\"precision\")\n",
    "print(f\"The Cross-validated precision is: {np.mean(cv_precision)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3150e193-a0de-4506-acc4-c2d35c602690",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f102e670-fd6c-4d59-a26f-e6dff1f1ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# cross-validation recall\n",
    "cv_recall = cross_val_score(clf, X, y, scoring=\"recall\")\n",
    "print(f\"The Cross-validated recall is: {np.mean(cv_recall)*100:.2f}%\")\n",
    "cv_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4d8ad1-4cec-4169-bf8d-5e319acbb65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Craete the data\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# split the data into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b53547a-f9b8-4658-b003-8c2f82e3c071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6545660727379677)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "cv_r2 = cross_val_score(model, X, y, cv=3, scoring=None)\n",
    "np.mean(cv_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fd63a4d-3ec0-4b68-a6b6-4b132835d5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62156808, 0.72076221, 0.62136792])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39acb419-8654-4c5e-af3c-44d3d1d8bc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-0.4811411446705427)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean absolute error\n",
    "cv_mae = cross_val_score(model, X, y, cv=3, scoring=\"neg_mean_absolute_error\")\n",
    "cv_mae\n",
    "np.mean(cv_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fdbf4c58-4dd8-4b6a-b3e1-f3fbbceb922e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-0.463292458220971)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean squared error \n",
    "cv_mse = cross_val_score(model, X, y, cv=3, scoring=\"neg_mean_squared_error\")\n",
    "cv_mse\n",
    "np.mean(cv_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff061e62-f181-4184-b824-f721da79531f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
